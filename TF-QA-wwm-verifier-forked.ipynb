{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load in \n\n# import collections\n# import enum\n# import numpy as np # linear algebra\n# import json\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# import re\n# import tensorflow.compat.v1 as tf\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import and flags\nimport albert_yes_no_fn_builder\nimport albert_yes_no_modeling\nimport albert_yes_no_utils\nimport bert_disjoint_fn_builder\nimport bert_disjoint_modeling\nimport bert_disjoint_utils\nimport create_submission\nimport json\nimport tensorflow.compat.v1 as tf\nimport tokenization\ntf.logging.set_verbosity(tf.logging.INFO)\ntf.disable_eager_execution()\n\ndef del_all_flags(FLAGS):\n    flags_dict = FLAGS._flags()\n    keys_list = [keys for keys in flags_dict]\n    for keys in keys_list:\n        FLAGS.__delattr__(keys)\n\ndel_all_flags(tf.app.flags.FLAGS)\nflags = tf.app.flags\n\n# bert\nflags.DEFINE_string(\"bert_config_file\", \"/kaggle/input/bert-disjoint/bert_config.json\", \" \")\nflags.DEFINE_string(\"vocab_file_bert\", \"/kaggle/input/bert-disjoint/vocab-nq.txt\", \" \")\nflags.DEFINE_string(\"output_dir_bert\", \"/kaggle/input/bert-disjoint/\", \" \")\nflags.DEFINE_string(\"init_checkpoint_bert\", \"/kaggle/input/bert-disjoint/model.ckpt-15000\", \" \")\n# albert\nflags.DEFINE_string(\"albert_config_file\", \"/kaggle/input/albert-yes-no/albert_config.json\", \" \")\nflags.DEFINE_string(\"vocab_file_albert\", \"/kaggle/input/albert-yes-no/30k-clean.vocab\", \" \")\nflags.DEFINE_string(\"spm_model_file\", \"/kaggle/input/albert-yes-no/30k-clean.model\", \" \")\nflags.DEFINE_string(\"output_dir_albert\", \"/kaggle/input/albert-yes-no/\", \" \")\nflags.DEFINE_string(\"init_checkpoint_albert\", \"/kaggle/input/albert-yes-no/model.ckpt-1206\", \" \")\n\nflags.DEFINE_string(\"eval_record_file_bert\", \"eval_bert.tf_record\", \" \")\n# flags.DEFINE_string(\"eval_record_file_albert\", \"eval_albert.tf_record\", \" \")\n\nflags.DEFINE_integer(\"max_seq_length\", 512, \" \")\nflags.DEFINE_integer(\"predict_batch_size\", 8, \" \")\n\n## Special flags - do not change\nflags.DEFINE_string(\n    \"predict_file\", \"/kaggle/input/tensorflow2-question-answering/simplified-nq-test.jsonl\",\n    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\nflags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\nflags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\nflags.DEFINE_string('f', '', 'kernel')\nflags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n\nFLAGS = flags.FLAGS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------ cell for extracting yes no questions ------------------\nkeyword_list = [\"are\", \"is\", \"was\", \"were\",\n                \"can\", \"could\", \"will\", \"would\", \"should\",\n                \"did\", \"do\", \"does\", \"has\", \"had\", \"have\"]\n\n\ndef is_yes_no_question(_question_text):\n    _text = _question_text.lower()\n    return (\"true or false\" in _text) or (_text.strip().split(\" \")[0] in keyword_list)\n\n\nwith open(FLAGS.predict_file, \"r\") as f, open(\"yes_no_questions.jsonl\", \"w\") as of:\n    for line in f:\n        question_text = json.loads(line)[\"question_text\"]\n        if is_yes_no_question(question_text):\n            of.write(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------ cell for bert-disjoint stage: example -> record ------------------\nbert_tokenizer = tokenization.FullTokenizer(vocab_file=FLAGS.vocab_file_bert, do_lower_case=True)\neval_examples = bert_disjoint_utils.read_nq_examples(input_file=FLAGS.predict_file)\neval_writer = bert_disjoint_utils.FeatureWriter(filename=FLAGS.eval_record_file_bert, is_training=False)\neval_features = []\n\n\ndef append_feature(feature):\n    eval_features.append(feature)\n    eval_writer.process_feature(feature)\n\n\nnum_spans_to_ids = bert_disjoint_utils.convert_examples_to_features(examples=eval_examples,\n                                                                    tokenizer=bert_tokenizer,\n                                                                    output_fn=append_feature)\neval_writer.close()\neval_filename = eval_writer.filename","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------ cell for bert-disjoint stage: inference ------------------\nbert_config = bert_disjoint_modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\nrun_config = tf.estimator.RunConfig(model_dir=FLAGS.output_dir_bert)\n\nmodel_fn = bert_disjoint_fn_builder.model_fn_builder(bert_config=bert_config,\n                                                     init_checkpoint=FLAGS.init_checkpoint_bert)\nestimator = tf.estimator.Estimator(model_fn=model_fn,\n                                   model_dir=FLAGS.output_dir_bert,\n                                   config=run_config,\n                                   params={\"batch_size\": FLAGS.predict_batch_size})\n\npredict_input_fn = bert_disjoint_fn_builder.input_fn_builder(input_file=eval_filename,\n                                                             seq_length=FLAGS.max_seq_length,\n                                                             drop_remainder=False)\n\ntf.logging.info(\"***** Running predictions *****\")\ntf.logging.info(\"  Num orig examples = %d\", len(eval_examples))\ntf.logging.info(\"  Num split examples = %d\", len(eval_features))\ntf.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\nfor spans, ids in num_spans_to_ids.items():\n    tf.logging.info(\"  Num split into %d = %d\", spans, len(ids))\n\nall_results = []\nfor result in estimator.predict(predict_input_fn, yield_single_examples=True):\n    if len(all_results) % 1000 == 0:\n        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n    unique_id = int(result[\"unique_ids\"])\n    start_logits = [float(x) for x in result[\"start_logits\"].flat]\n    end_logits = [float(x) for x in result[\"end_logits\"].flat]\n    all_results.append(bert_disjoint_utils.RawResult(unique_id=unique_id,\n                                                     start_logits=start_logits,\n                                                     end_logits=end_logits))\n\ncandidates_dict = bert_disjoint_utils.read_candidates(FLAGS.predict_file)\neval_features = [tf.train.Example.FromString(r) for r in tf.python_io.tf_record_iterator(eval_filename)]\nnq_pred_dict = bert_disjoint_utils.compute_pred_dict(candidates_dict, eval_features, [r._asdict() for r in all_results])\npredictions = list(nq_pred_dict.values())\n\n# ------------------ clean up ------------------\ndel bert_config, run_config, model_fn, estimator, predict_input_fn\ndel all_results, candidates_dict, eval_features, nq_pred_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------ cell for yes-no correction stage: example -> record ------------------\nalbert_tokenizer = tokenization.FullTokenizer(vocab_file=FLAGS.vocab_file_albert,\n                                              do_lower_case=True,\n                                              spm_model_file=FLAGS.spm_model_file)\neval_examples = albert_yes_no_utils.read_nq_examples(input_file=\"yes_no_questions.jsonl\")\neval_writer = albert_yes_no_utils.FeatureWriter(filename=\"yes_no_questions.eval.tf_record\",\n                                                albert_tokenizer=albert_tokenizer)\nn_features, example_to_feature_map, feature_to_example_map = \\\n    eval_writer.file_based_convert_examples_to_features_span(eval_examples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------ cell for yes-no correction stage: inference ------------------\nalbert_config = albert_yes_no_modeling.AlbertConfig.from_json_file(FLAGS.albert_config_file)\nrun_config = tf.estimator.RunConfig(model_dir=FLAGS.output_dir_albert)\n\nmodel_fn = albert_yes_no_fn_builder.model_fn_builder(albert_config=albert_config,\n                                                     init_checkpoint=FLAGS.init_checkpoint_albert)\n\nestimator = tf.estimator.Estimator(model_fn=model_fn,\n                                   model_dir=FLAGS.output_dir_albert,\n                                   config=run_config,\n                                   params={\"batch_size\": FLAGS.predict_batch_size})\n\npredict_input_fn = albert_yes_no_fn_builder.input_fn_builder(input_file=\"yes_no_questions.eval.tf_record\",\n                                                             seq_length=FLAGS.max_seq_length,\n                                                             drop_remainder=False)\n\ntf.logging.info(\"  Num features: %d\" % n_features)\nall_results = []\nfor result in estimator.predict(predict_input_fn, yield_single_examples=True):\n    if len(all_results) % 100 == 0:\n        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n\n    answer_type_logits = [float(x) for x in result[\"answer_type_logits\"].flat]\n    all_results.append(answer_type_logits)\n\nyes_no_pred_dict = albert_yes_no_utils.compute_pred_dicts_cls(\"yes_no_questions.jsonl\",\n                                                              all_results,\n                                                              example_to_feature_map,\n                                                              feature_to_example_map)\n\n# ------------------ clean up ------------------\ndel albert_config, run_config, model_fn, estimator, predict_input_fn\ndel all_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------ final cell for creating submission ------------------\ncreate_submission.merge_predictions(predictions, yes_no_pred_dict)\ncreate_submission.create_answers(predictions, \"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}